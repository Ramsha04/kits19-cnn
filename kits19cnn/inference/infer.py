import numpy as np
import nibabel as nib
import pandas as pd
import os

from kits19cnn.io.preprocess import Preprocessor
from pathlib import Path
from os.path import join, isdir
from scipy.ndimage.filters import gaussian_filter
from batchgenerators.augmentations.utils import pad_nd_image
from kits19cnn.models.metrics import evaluate_official

class Predictor(Preprocessor):
    """
    Prediction with Test-Time Data Augmentation & Post-Processing
    """
    def __init__(self, model, weights_path, in_dir, out_dir, coords_csv_path=None, from_logits=True,
                 clip_values=None, cases=None, do_mirroring=True, use_gaussian=False, n_repeats=1,
                 regions_class_order=None, save_as_slices=False):
        """
        Attributes:
            model: channels_first
            weights_path (str): Path to the .h5 file with the trained weights
            in_dir (str): directory with the input data. Should be the kits19/data directory or when coords_csv_path is provided, it's where
                your preprocessed dataset, created by `io.preprocess.Preprocessor`, is located.
            out_dir (str): output directory where you want to save each prediction.
            coords_csv_path (str): path to the coords.csv file generated by io.preprocess.Predictor. Defaults to None.
                Note that coords_csv_path and in_dir cannot be both None because when coords_csv_path is None, the
                test set is preprocessed from in_dir. So, please specify one.
            clip_values (list, tuple): values you want to clip CT scans to
                * For whole dset, the [0.5, 99.5] percentiles are [-75.75658734213053, 349.4891265535317]
            cases: list of case folders to preprocess
            do_mirroring (boolean): whether or not you want to predict on all possible mirrored results
            use_gaussian (boolean): test-time gaussian noise
            n_repeats (int): Number of times to repeat the prediction process
            regions_class_order (tuple or None): classes you want the corresponding predicted labels to contain
        """
        super().__init__(in_dir=in_dir, out_dir=out_dir, clip_values=clip_values, cases=cases, save_as_slices=save_as_slices)
        if self.save_as_slices:
            print("WARNING: Predictor does not support save_as_slices=True. Please use BinaryPredictor.")
        self.model = model
        if from_logits:
            self.load_model_from_logits_softmax(weights_path)
        elif not from_logits:
            self.model.load_weights(weights_path)
        # reading csv
        try:
            self.coords_csv = pd.read_csv(coords_csv_path, index_col="cases").drop('Unnamed: 0', axis=1)
        except ValueError: # when coords_csv_path=None
            print("WARNING: Going to preprocess the test set from scratch.")
            self.coords_csv = None

        self.do_mirroring = do_mirroring
        self.use_gaussian = use_gaussian
        self.patch_size = model.inputs[0].shape.as_list()[-2:]
        self.n_classes = model.outputs[0].shape.as_list()[1]
        self.n_repeats = n_repeats
        self.regions_class_order = regions_class_order

    def predict(self, evaluate=True):
        """
        Main prediction function. Saves predictions, images, labels
        """
        # Generating data and saving them recursively
        tk_dices = []
        tu_dices = []
        for (i, case) in enumerate(self.cases):
            print("Processing {0}/{1}: {2}".format(i+1, len(self.cases), case))
            if self.coords_csv is None:
                image = nib.load(join(case, "imaging.nii.gz")).get_fdata()
                label = nib.load(join(case, "segmentation.nii.gz")).get_fdata()
                orig_shape = image.shape
                # preprocessing
                preprocessed_img, preprocessed_label, coords = self.preprocess_2d(image, label)
                self.save_imgs(preprocessed_img, preprocessed_label, case)
            else:
                preprocessed_img = np.load(join(case, "imaging.npy"))
                preprocessed_label = np.load(join(case, "segmentation.npy"))
                coords, orig_shape = self.parse_coords_csv(case)

            preprocessed_img = np.expand_dims(preprocessed_img, 0)
            preprocessed_label = np.expand_dims(preprocessed_label, 0)
            # predicting + post-processing
            pred, act_pred = self.predict_3D_2Dconv_tiled(preprocessed_img)
            pred = pad_nonint_extraction(pred, orig_shape, coords, pad_border_mode="constant")
            self.save_predictions(pred, act_pred, case=case)
            if evaluate:
                label = nib.load(join(case, "segmentation.nii.gz")).get_fdata()
                tk_dice, tu_dice = evaluate_official(label, pred)
                print("Tumour and Kidney Dice: {0}; Tumour Dice: {1}".format(tk_dice, tu_dice))
                tk_dices.append(tk_dice), tu_dices.append(tu_dice)
        if evaluate:
            print("Average Tumour Kidney Dice: {0}\n".format(np.mean(tk_dices)) +
                  "Average Tumour Dice: {0}\n".format(np.mean(tu_dices)))

    def predict_3D_2Dconv_tiled(self, data, BATCH_SIZE=None, mirror_axes=(0, 1),
                                step=2, pad_border_mode="edge", pad_kwargs=None):
        """
        Args:
            data (numpy array): shape of (c, x, y, z)
            BATCH_SIZE (int): Batch size
            mirror_axes (list, tuple): for each spatial dimension (0,1)
            steps (int):
            pad_border_mode (str):
            pad_kwargs:
        """
        assert len(data.shape) == 4, "data must be c, x, y, z"
        predicted_segmentation = []
        act_pred = []
        for s in range(data.shape[1]):
            pred_seg, act_pres = \
                self.predict_2D_2Dconv_tiled(data[:, s], BATCH_SIZE, step,
                                             mirror_axes, pad_border_mode=pad_border_mode,
                                             pad_kwargs=pad_kwargs)
            predicted_segmentation.append(pred_seg[None])
            act_pred.append(act_pres[None])
        predicted_segmentation = np.vstack(predicted_segmentation)
        act_pred = np.vstack(act_pred).transpose((1, 0, 2, 3))
        return predicted_segmentation, act_pred

    def predict_2D_2Dconv_tiled(self, patient_data, BATCH_SIZE=None, step=2,
                                mirror_axes=(0, 1), pad_border_mode="edge", pad_kwargs=None):
        """
        Args:
            patient_data: shape of (c, x, y)
            BATCH_SIZE (int): Batch size
            mirror_axes (list, tuple): for each spatial dimension (0,1)
            steps (int):
            pad_border_mode (str):
            pad_kwargs:
        """
        tile_size = self.patch_size
        assert tile_size is not None, "patch_size cannot be None for tiled prediction"
        # pad images so that their size is a multiple of tile_size
        data, slicer = pad_nd_image(patient_data, tile_size, pad_border_mode, pad_kwargs, True)
        # adds the channels dimension
        data = data[None]

        if BATCH_SIZE is not None:
            data = np.vstack([data] * BATCH_SIZE)

        input_size = [1, patient_data.shape[0]] + list(tile_size)
        input_size = [int(i) for i in input_size] # rounding

        result = np.zeros([self.n_classes] + list(data.shape[2:]), dtype=np.float32)
        result_numsamples = np.zeros([self.n_classes] + list(data.shape[2:]), dtype=np.float32)
        if self.use_gaussian:
            tmp = np.zeros(tile_size, dtype=np.float32)
            center_coords = [i//2 for i in tile_size]
            sigmas = [i // 8 for i in tile_size]
            tmp[tuple(center_coords)] = 1
            tmp_smooth = gaussian_filter(tmp, sigmas, 0, mode='constant', cval=0)
            tmp_smooth = tmp_smooth / tmp_smooth.max() * 1
            add = tmp_smooth
        else:
            add = np.ones(tile_size)

        data_shape = data.shape
        center_coord_start = np.array([dim//2 for dim in self.patch_size]).astype(int) #lb center of patch
        # i+2 because of batch size and channels dimension
        # ub center coords
        center_coord_end = np.array([data_shape[i + 2] - self.patch_size[i] // 2 for i in range(len(self.patch_size))]).astype(int)
        # number of total steps to extract from based on the specified step size
        n_steps = np.ceil([(center_coord_end[i] - center_coord_start[i]) / (self.patch_size[i] / step) for i in range(2)])
        # how big each step based on the number steps and the coords
        # Why use the center coordinates? b/c better results? cleaner crop
        step_size = np.array([(center_coord_end[i] - center_coord_start[i]) / (n_steps[i] + 1e-8) for i in range(2)])
        step_size[step_size == 0] = 9999999 # what does this deal with? when n_steps = 0, so when the patch size is close to
                                            # the data shape
        # center patch coords to extract from
        xsteps = np.round(np.arange(center_coord_start[0], center_coord_end[0]+1e-8, step_size[0])).astype(int)
        ysteps = np.round(np.arange(center_coord_start[1], center_coord_end[1]+1e-8, step_size[1])).astype(int)
        # center cropping at each coordinate
        for x in xsteps:
            lb_x = x - self.patch_size[0] // 2
            ub_x = x + self.patch_size[0] // 2
            for y in ysteps:
                lb_y = y - self.patch_size[1] // 2
                ub_y = y + self.patch_size[1] // 2
                result[:, lb_x:ub_x, lb_y:ub_y] += \
                    self.pred_per_2D(data[:, :, lb_x:ub_x, lb_y:ub_y], mirror_axes, add).squeeze()
                # important for averaging
                result_numsamples[:, lb_x:ub_x, lb_y:ub_y] += add
        # Removing the padding that was added in the beginning by pad_nd_image
        slicer = tuple([slice(0, result.shape[i]) for i in range(len(result.shape) - (len(slicer) - 1))] + slicer[1:])
        result = result[slicer]
        result_numsamples = result_numsamples[slicer]
        # completing the averaging
        act_pred = result / result_numsamples

        if self.regions_class_order is None:
            predicted_segmentation = act_pred.argmax(0)
        else:
            predicted_segmentation_shp = act_pred[0].shape
            predicted_segmentation = np.zeros(predicted_segmentation_shp, dtype=np.float32)
            for i, c in enumerate(self.regions_class_order):
                predicted_segmentation[act_pred[i] > 0.5] = c
        return predicted_segmentation, act_pred

    def pred_per_2D(self, x, mirror_axes, mult=None):
        """
        Args:
            x: numpy array
            mirror_axes (list, tuple): for each spatial dimension (0,1)
            mult (boolean): factor to multiply results by
        """
        result = np.zeros([1, self.n_classes] + list(x.shape[2:]))
        n_results = self.n_repeats
        if self.do_mirroring:
            mirror_idx = 4
            n_results *= 2 ** len(mirror_axes)
        else:
            mirror_idx = 1

        for i in range(self.n_repeats):
            for m in range(mirror_idx):
                if m == 0:
                    pred = self.model.predict(x)
                    result += 1/n_results * pred

                if m == 1 and (1 in mirror_axes):
                    pred = self.model.predict(np.flip(x, 3))
                    result += 1/n_results * np.flip(pred, 3)

                if m == 2 and (0 in mirror_axes):
                    pred = self.model.predict(np.flip(x, 2))
                    result += 1/n_results * np.flip(pred, 2)

                if m == 3 and (0 in mirror_axes) and (1 in mirror_axes):
                    pred = self.model.predict(np.flip(np.flip(x, 3), 2))
                    result += 1/n_results * np.flip(np.flip(pred, 3), 2)

        if mult is not None:
            result[:, :] *= mult

        return result

    def load_model_from_logits_softmax(self, weights_path):
        """
        Loads model weights and tacks on an extra softmax layer; used when model returns
        logits instead of output probabilities.
        Args:
            weights_path: path to the weights
        Returns:
            None
            Just sets self.model to the new model
        """
        from tensorflow.keras.models import Model
        from tensorflow.keras.layers import Softmax
        import tensorflow.keras.backend as K
        K.set_image_data_format("channels_first")
        self.model.load_weights(weights_path)
        inp = self.model.input
        logits = self.model.output
        act = Softmax(axis=1)(logits)
        self.model = Model(inputs=[inp], outputs=[act])

    def parse_coords_csv(self, case_path):
        """
        Args:
            case (str): case folder name
        Returns:
            list of lists of [lb, ub] (in the format of the output of extract_nonint_region)
        """
        # case -> filepath, so need to just get the case id
        case = Path(case_path).name
        coords_cols = [("z_lb", "z_ub"), ("x_lb", "x_ub"), ("y_lb", "y_ub")]
        shape_cols = ["orig_z", "orig_x", "orig_y"]
        # iterating through tuples of column names
        coords_list = [[int(self.coords_csv.loc[case, coords[0]]), int(self.coords_csv.loc[case, coords[1]])] for coords in coords_cols]
        # iterating through each columns' dimension
        orig_shape = tuple([int(self.coords_csv.loc[case, col]) for col in shape_cols])
        return coords_list, orig_shape

    def save_predictions(self, pred, pred_act, case):
        """
        Saves a prediction as a .npy array in the KiTS19 file structure
        Args:
            pred: numpy array
            pred_act: The raw outputted probability map from your NN
            case: path to a case folder (each element of self.cases)
        Returns:
            None
        """
        # extracting the raw case folder name
        case = Path(case).name
        out_case_dir = join(self.out_dir, case)
        # checking to make sure that the output directories exist
        if not isdir(out_case_dir):
            os.mkdir(out_case_dir)
            print("Created directory: {0}".format(out_case_dir))

        save_name = "pred_{0}.npy".format(case)
        save_name_act = "pred_{0}_act.npy".format(case)
        np.save(join(out_case_dir, save_name), pred)
        np.save(join(out_case_dir, save_name_act), pred_act)
        print("Saving predictions: {0}, {1}".format(save_name, save_name_act))

class FromSliceDataPredictor(Predictor):
    """
    Prediction with Test-Time Data Augmentation & Post-Processing;
    For binary cases and assumes that the input data is coming in as 2D slices.
    Does no evaluation.
    """
    def __init__(self, model, weights_path, in_dir, out_dir, coords_csv_path, from_logits=True,
                 cases=None, do_mirroring=True, use_gaussian=False, n_repeats=1, regions_class_order=None, multi_output=True):
        """
        Attributes:
            model: channels_first
            weights_path (str): Path to the .h5 file with the trained weights
            in_dir (str): directory with the input data. Should be the kits19/data directory or when coords_csv_path is provided, it's where
                your preprocessed dataset, created by `io.preprocess.Preprocessor`, is located.
            out_dir (str): output directory where you want to save each prediction.
            coords_csv_path (str): path to the coords.csv file generated by io.preprocess.Predictor. Defaults to None.
                Note that coords_csv_path and in_dir cannot be both None because when coords_csv_path is None, the
                test set is preprocessed from in_dir. So, please specify one.
            cases: list of case folders to preprocess
            do_mirroring (boolean): whether or not you want to predict on all possible mirrored results
            use_gaussian (boolean): test-time gaussian noise
            n_repeats (int): Number of times to repeat the prediction process
            regions_class_order (tuple or None): classes you want the corresponding predicted labels to contain
            multi_output (bool):
                * True; if using the Attention U-Net
                * False; if using single-outputted networks
        """
        ## NOTE: clip values does not matter in this case because data has already been preprocessed beforehand
        super().__init__(model=model, weights_path=weights_path, in_dir=in_dir, out_dir=out_dir, from_logits=from_logits, coords_csv_path=coords_csv_path,
                         clip_values=[-75.8, 349.5], cases=cases, do_mirroring=do_mirroring, use_gaussian=use_gaussian, n_repeats=n_repeats,
                         regions_class_order=regions_class_order, save_as_slices=True)

        self.multi_output = multi_output

    def predict(self, standardize=True, mean_std=None, standardize_on_the_fly=True, standardize_whole=True):
        """
        Main prediction function. Saves predictions.
        Args:
            standardize (bool): whether or not to standardize the input
            mean_std (list/tuple): of [mean, std]; only when standardize=True and standardize_on_the_fly=False
            standardize_on_the_fly (bool): whether or not to apply z-score standardization per slice instead of using
                mean_std
        """
        # Generating data and saving them recursively
        tk_dices = []
        tu_dices = []
        for (i, case) in enumerate(self.cases):
            print("Processing {0}/{1}: {2}".format(i+1, len(self.cases), case))
            # creating list of paths to all imaging slice .npy files in the directory
            case_dir = join(self.in_dir, case)
            all_imaging = [join(case_dir, file) for file in os.listdir(case_dir)
                           if file.startswith("imaging_")]

            preprocessed_img = np.stack([np.load(slice_) for slice_ in all_imaging])
            if standardize:
                preprocessed_img = self.standardize(preprocessed_img, mean_std, standardize_on_the_fly, standardize_whole)
            coords, orig_shape = self.parse_coords_csv(case)
            preprocessed_img = np.expand_dims(preprocessed_img, 0)
            # predicting + post-processing
            pred, act_pred = self.predict_3D_2Dconv_tiled(preprocessed_img)
            pred = pad_nonint_extraction(pred, orig_shape, coords, pad_border_mode="constant")
            self.save_predictions(pred, act_pred, case=case)

    def pred_per_2D(self, x, mirror_axes, mult=None):
        """
        Args:
            x: numpy array
            mirror_axes (list, tuple): for each spatial dimension (0,1)
            mult (boolean): factor to multiply results by
        """
        result = np.zeros([1, self.n_classes] + list(x.shape[2:]))
        n_results = self.n_repeats
        if self.do_mirroring:
            mirror_idx = 4
            n_results *= 2 ** len(mirror_axes)
        else:
            mirror_idx = 1

        for i in range(self.n_repeats):
            for m in range(mirror_idx):
                if m == 0:
                    pred = self.model.predict(x) if not self.multi_output else self.model.predict(x)[-1]
                    result += 1/n_results * pred

                if m == 1 and (1 in mirror_axes):
                    input_img = np.flip(x, 3)
                    pred = self.model.predict(input_img) if not self.multi_output else self.model.predict(input_img)[-1]
                    result += 1/n_results * np.flip(pred, 3)

                if m == 2 and (0 in mirror_axes):
                    input_img = np.flip(x, 2)
                    pred = self.model.predict(input_img) if not self.multi_output else self.model.predict(input_img)[-1]
                    result += 1/n_results * np.flip(pred, 2)

                if m == 3 and (0 in mirror_axes) and (1 in mirror_axes):
                    input_img = np.flip(np.flip(x, 3), 2)
                    pred = self.model.predict(input_img) if not self.multi_output else self.model.predict(input_img)[-1]
                    result += 1/n_results * np.flip(np.flip(pred, 3), 2)

        if mult is not None:
            result[:, :] *= mult

        return result

    def standardize(self, img, mean_std=None, standardize_on_the_fly=True, standardize_whole=True):
        """
        Handles the z-score standardization based on mean_std or does it per-slice if
        standardize_on_the_fly is True.
        Args:
            standardize_whole (bool): whether or not to standardize the whole 3d volume or per slice
        """
        def standardize_array(arr, mean, std):
            orig_shape = arr.shape
            arr = arr.flatten()
            normalized = (arr-mean) / std
            return normalized.reshape(orig_shape)
        # standardization
        if standardize_whole:
            # standardizing the whole volume
            mean, std = (img.mean(), img.std()) if standardize_on_the_fly else mean_std
            norm_img = standardize_array(img, mean, std)
        else:
            # standardize per 2d slice; not compatible with mean_std
            norm_img = np.stack([standardize_array(arr, arr.mean(), arr.std()) for arr in img])
        return norm_img

def pad_nonint_extraction(image, orig_shape, coords, pad_border_mode="edge", pad_kwargs={}):
    """
    Pads the cropped output from the extract_nonint_region function
    Args:
        image: either the mask or the thresholded (= 0.5) segmentation prediction (x, y, z)
        orig_shape: Original shape of the 3D volume (no channels)
        coords: outputted coordinates from `extract_nonint_region`
    Returns:
        padded: numpy array of shape `orig_shape`
    """
    # reversing the cropping with padding
    padding = [[coords[i][0], orig_shape[i]-coords[i][1]] for i in range(len(orig_shape))]
    padded = np.pad(image, padding, mode=pad_border_mode, **pad_kwargs)
    return padded
